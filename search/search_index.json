{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview RNAsamba is a tool for computing the coding potential of RNA sequences using a neural network classification model. It can be used to identify mRNAs and lncRNAs without relying on database searches. For details of RNAsamba's methods, check the Theory section or read our article . Web version RNAsamba can be used through a minimal web interface that is freely available online . Source code RNAsamba is an open source package distributed under the GPL-3.0 license. Its source code can be found in the GitHub repository . The source code of the web version is also available in GitHub . Citation Camargo, A. P., Sourkov, V., Pereira, G. A. G. & Carazzolle, M. F.. \" RNAsamba: neural network-based assessment of the protein-coding potential of RNA sequences \" NAR Genomics and Bioinformatics 2 , lqz024 (2020).","title":"Home"},{"location":"#overview","text":"RNAsamba is a tool for computing the coding potential of RNA sequences using a neural network classification model. It can be used to identify mRNAs and lncRNAs without relying on database searches. For details of RNAsamba's methods, check the Theory section or read our article .","title":"Overview"},{"location":"#web-version","text":"RNAsamba can be used through a minimal web interface that is freely available online .","title":"Web version"},{"location":"#source-code","text":"RNAsamba is an open source package distributed under the GPL-3.0 license. Its source code can be found in the GitHub repository . The source code of the web version is also available in GitHub .","title":"Source code"},{"location":"#citation","text":"Camargo, A. P., Sourkov, V., Pereira, G. A. G. & Carazzolle, M. F.. \" RNAsamba: neural network-based assessment of the protein-coding potential of RNA sequences \" NAR Genomics and Bioinformatics 2 , lqz024 (2020).","title":"Citation"},{"location":"installation/","text":"Installation Installation methods There are two methods to install RNAsamba in your computer: Using pip: pip install rnasamba Using conda: conda install -c conda-forge -c bioconda rnasamba Using RNAsamba with a GPU If you want to use RNAsamba with a GPU, you first need to install tensorflow-gpu>=1.5.0,<2.0 , keras>=2.1.0,<2.3.0 , numpy<=1.16.5 and biopython with pip and then proceed to install rnasamba using the --no-deps argument. Docker We provide a Docker image for RNAsamba. You can check how to use it in the usage documentation .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#installation-methods","text":"There are two methods to install RNAsamba in your computer: Using pip: pip install rnasamba Using conda: conda install -c conda-forge -c bioconda rnasamba Using RNAsamba with a GPU If you want to use RNAsamba with a GPU, you first need to install tensorflow-gpu>=1.5.0,<2.0 , keras>=2.1.0,<2.3.0 , numpy<=1.16.5 and biopython with pip and then proceed to install rnasamba using the --no-deps argument.","title":"Installation methods"},{"location":"installation/#docker","text":"We provide a Docker image for RNAsamba. You can check how to use it in the usage documentation .","title":"Docker"},{"location":"theory/","text":"Theory IGLOO sequence representations Traditionally, recurrent neural networks (RNNs) are the go-to models to create high level representations from sequence data. However, these networks don't perform well with long sequences and their training can be very slow. To achieve better classification performance and speed, RNAsamba uses the recently introduced IGLOO architecture 1 , which looks at sequences as a whole, rather than sequentially like in the recurrent paradigm. To do so, IGLOO creates representations of sequences by taking patches of the feature space and multiplying them by learnable weights. By taking global snapshots of the sequence, IGLOO networks can be used to process very long sequences, making them particularly interesting for nucleotide sequence data. Two branch structure Starting from the initial nucleotide sequence, RNAsamba computes the coding potential of a given transcript by combining information coming from two different sources: the Whole Sequence Branch (B 1 ) and the Longest ORF Branch (B 2 ). B 1 contains whole sequence representations of the transcript and can capture protein-coding signatures irrespective of the identification of the ORF. In contrast, B 2 carries information extracted from the longest identified ORF and the putative protein translated from it. By taking into account these two sources of sequence information, RNAsamba builds a thorough model of the transcript, improving the classification performance of the algorithm. For a more detailed description of RNAsamba's algorithm, please check our article . Sourkov, Vsevolod. \"IGLOO: Slicing the Features Space to Represent Long Sequences.\" arXiv (2018). \u21a9","title":"Theory"},{"location":"theory/#theory","text":"","title":"Theory"},{"location":"theory/#igloo-sequence-representations","text":"Traditionally, recurrent neural networks (RNNs) are the go-to models to create high level representations from sequence data. However, these networks don't perform well with long sequences and their training can be very slow. To achieve better classification performance and speed, RNAsamba uses the recently introduced IGLOO architecture 1 , which looks at sequences as a whole, rather than sequentially like in the recurrent paradigm. To do so, IGLOO creates representations of sequences by taking patches of the feature space and multiplying them by learnable weights. By taking global snapshots of the sequence, IGLOO networks can be used to process very long sequences, making them particularly interesting for nucleotide sequence data.","title":"IGLOO sequence representations"},{"location":"theory/#two-branch-structure","text":"Starting from the initial nucleotide sequence, RNAsamba computes the coding potential of a given transcript by combining information coming from two different sources: the Whole Sequence Branch (B 1 ) and the Longest ORF Branch (B 2 ). B 1 contains whole sequence representations of the transcript and can capture protein-coding signatures irrespective of the identification of the ORF. In contrast, B 2 carries information extracted from the longest identified ORF and the putative protein translated from it. By taking into account these two sources of sequence information, RNAsamba builds a thorough model of the transcript, improving the classification performance of the algorithm. For a more detailed description of RNAsamba's algorithm, please check our article . Sourkov, Vsevolod. \"IGLOO: Slicing the Features Space to Represent Long Sequences.\" arXiv (2018). \u21a9","title":"Two branch structure"},{"location":"usage/","text":"Using RNAsamba locally Download the pre-trained models What is a weights file? When a neural network classification model is trained the information it learns is numerically encoded in its weights. In order to use RNAsamba to classify your own sequences, you need to load weights obtained in a previous training iteration. We provide two HDF5 files containing the weights of classification models trained with human trancript sequences. The first model ( full_length_weights.hdf5 ) was trained with full-length transcripts and can be used in datasets comprised mostly or exclusively of complete transcript sequences. The second model ( partial_length_weights.hdf5 ) was trained with both complete and truncated transcripts and is prefered in cases where there is a significant fraction of partial-length sequences, such as transcriptomes assembled using de novo approaches. Both models achieve high classification performance in transcripts from a variety of different species (see our article ). For most cases, we reccomend using full_length_weights.hdf5 , unless you have a reason to suspect that your data contain a significative amount of truncated transcripts. Full-length transcripts Partial-length transcripts Alternatively, you can download the weight files in an command-line interface by executing the following commands: curl -O https://raw.githubusercontent.com/apcamargo/RNAsamba/master/data/full_length_weights.hdf5 curl -O https://raw.githubusercontent.com/apcamargo/RNAsamba/master/data/partial_length_weights.hdf5 In case you want to train your own model, you should follow the steps described in the rnasamba train section. rnasamba train rnasamba train is the command for training a new classification model from a training dataset and saving the network weights into an HDF5 file. The user can specify the batch size ( --batch_size ) and the number of training epochs ( --epochs ). The user can also choose to activate early stopping ( --early_stopping ), which reduces training time and can help avoiding overfitting. usage : rnasamba train [- h ] [- s EARLY_STOPPING ] [- b BATCH_SIZE ] [- e EPOCHS ] [- v { 0 , 1 , 2 , 3 }] output_file coding_file noncoding_file Train a new classification model . positional arguments : output_file output HDF5 file containing weights of the newly trained RNAsamba network . coding_file input FASTA file containing sequences of protein - coding transcripts . noncoding_file input FASTA file containing sequences of noncoding transcripts . optional arguments : - h , -- help show this help message and exit -- version show program ' s version number and exit - s EARLY_STOPPING , -- early_stopping EARLY_STOPPING number of epochs after lowest validation loss before stopping training ( a fraction of 0.1 of the training set is set apart for validation and the model with the lowest validation loss will be saved ). ( default : 0 ) - b BATCH_SIZE , -- batch_size BATCH_SIZE number of samples per gradient update . ( default : 128 ) - e EPOCHS , -- epochs EPOCHS number of epochs to train the model . ( default : 40 ) - v { 0 , 1 , 2 , 3 }, -- verbose { 0 , 1 , 2 , 3 } print the progress of the training . 0 = silent , 1 = current step , 2 = progress bar , 3 = one line per epoch . ( default : 0 ) rnasamba classify rnasamba classify is the command for computing the coding potential of transcripts contained in an input FASTA file and classifying them into coding or non-coding. Optionally, the user can specify an output FASTA file ( --protein_fasta ) in which RNAsamba will write the translated sequences of the predicted coding ORFs. If multiple weight files are provided, RNAsamba will ensemble their predictions into a single output. usage : rnasamba classify [- h ] [- p PROTEIN_FASTA ] [- v { 0 , 1 }] output_file fasta_file weights [ weights ...] Classify sequences from a input FASTA file . positional arguments : output_file output TSV file containing the results of the classification . fasta_file input FASTA file containing transcript sequences . weights input HDF5 file ( s ) containing weights of a trained RNAsamba network ( if more than a file is provided , an ensembling of the models will be performed ). optional arguments : - h , -- help show this help message and exit -- version show program ' s version number and exit - p PROTEIN_FASTA , -- protein_fasta PROTEIN_FASTA output FASTA file containing translated sequences for the predicted coding ORFs . ( default : None ) - v { 0 , 1 }, -- verbose { 0 , 1 } print the progress of the classification . 0 = silent , 1 = current step . ( default : 0 ) Examples Training a new classification model using Mus musculus data downloaded from GENCODE: rnasamba train -v 2 mouse_model.hdf5 gencode.vM21.pc_transcripts.fa gencode.vM21.lncRNA_transcripts.fa Classifying sequences using our pre-trained model ( partial_length_weights.hdf5 ) and saving the predicted proteins into a FASTA file: rnasamba classify -p predicted_proteins.fa classification.tsv input.fa partial_length_weights.hdf5 head classification . tsv sequence_name coding_score classification ENSMUST00000054910 0 . 99022 coding ENSMUST00000059648 0 . 84718 coding ENSMUST00000055537 0 . 99713 coding ENSMUST00000030975 0 . 85189 coding ENSMUST00000050754 0 . 02638 noncoding ENSMUST00000008011 0 . 14949 noncoding ENSMUST00000061643 0 . 03456 noncoding ENSMUST00000059704 0 . 89232 coding ENSMUST00000036304 0 . 03782 noncoding Using the Docker image # Pull the Docker image to your computer : docker pull antoniopcamargo / rnasamba # Training example : docker run - ti --rm -v \"$(pwd):/app\" antoniopcamargo/rnasamba train -v 2 mouse_model.hdf5 gencode.vM21.pc_transcripts.fa gencode.vM21.lncRNA_transcripts.fa # Classification example : docker run - ti --rm -v \"$(pwd):/app\" antoniopcamargo/rnasamba classify -p predicted_proteins.fa classification.tsv input.fa full_length_weights.hdf5","title":"Using RNAsamba locally"},{"location":"usage/#using-rnasamba-locally","text":"","title":"Using RNAsamba locally"},{"location":"usage/#download-the-pre-trained-models","text":"What is a weights file? When a neural network classification model is trained the information it learns is numerically encoded in its weights. In order to use RNAsamba to classify your own sequences, you need to load weights obtained in a previous training iteration. We provide two HDF5 files containing the weights of classification models trained with human trancript sequences. The first model ( full_length_weights.hdf5 ) was trained with full-length transcripts and can be used in datasets comprised mostly or exclusively of complete transcript sequences. The second model ( partial_length_weights.hdf5 ) was trained with both complete and truncated transcripts and is prefered in cases where there is a significant fraction of partial-length sequences, such as transcriptomes assembled using de novo approaches. Both models achieve high classification performance in transcripts from a variety of different species (see our article ). For most cases, we reccomend using full_length_weights.hdf5 , unless you have a reason to suspect that your data contain a significative amount of truncated transcripts. Full-length transcripts Partial-length transcripts Alternatively, you can download the weight files in an command-line interface by executing the following commands: curl -O https://raw.githubusercontent.com/apcamargo/RNAsamba/master/data/full_length_weights.hdf5 curl -O https://raw.githubusercontent.com/apcamargo/RNAsamba/master/data/partial_length_weights.hdf5 In case you want to train your own model, you should follow the steps described in the rnasamba train section.","title":"Download the pre-trained models"},{"location":"usage/#rnasamba-train","text":"rnasamba train is the command for training a new classification model from a training dataset and saving the network weights into an HDF5 file. The user can specify the batch size ( --batch_size ) and the number of training epochs ( --epochs ). The user can also choose to activate early stopping ( --early_stopping ), which reduces training time and can help avoiding overfitting. usage : rnasamba train [- h ] [- s EARLY_STOPPING ] [- b BATCH_SIZE ] [- e EPOCHS ] [- v { 0 , 1 , 2 , 3 }] output_file coding_file noncoding_file Train a new classification model . positional arguments : output_file output HDF5 file containing weights of the newly trained RNAsamba network . coding_file input FASTA file containing sequences of protein - coding transcripts . noncoding_file input FASTA file containing sequences of noncoding transcripts . optional arguments : - h , -- help show this help message and exit -- version show program ' s version number and exit - s EARLY_STOPPING , -- early_stopping EARLY_STOPPING number of epochs after lowest validation loss before stopping training ( a fraction of 0.1 of the training set is set apart for validation and the model with the lowest validation loss will be saved ). ( default : 0 ) - b BATCH_SIZE , -- batch_size BATCH_SIZE number of samples per gradient update . ( default : 128 ) - e EPOCHS , -- epochs EPOCHS number of epochs to train the model . ( default : 40 ) - v { 0 , 1 , 2 , 3 }, -- verbose { 0 , 1 , 2 , 3 } print the progress of the training . 0 = silent , 1 = current step , 2 = progress bar , 3 = one line per epoch . ( default : 0 )","title":"rnasamba train"},{"location":"usage/#rnasamba-classify","text":"rnasamba classify is the command for computing the coding potential of transcripts contained in an input FASTA file and classifying them into coding or non-coding. Optionally, the user can specify an output FASTA file ( --protein_fasta ) in which RNAsamba will write the translated sequences of the predicted coding ORFs. If multiple weight files are provided, RNAsamba will ensemble their predictions into a single output. usage : rnasamba classify [- h ] [- p PROTEIN_FASTA ] [- v { 0 , 1 }] output_file fasta_file weights [ weights ...] Classify sequences from a input FASTA file . positional arguments : output_file output TSV file containing the results of the classification . fasta_file input FASTA file containing transcript sequences . weights input HDF5 file ( s ) containing weights of a trained RNAsamba network ( if more than a file is provided , an ensembling of the models will be performed ). optional arguments : - h , -- help show this help message and exit -- version show program ' s version number and exit - p PROTEIN_FASTA , -- protein_fasta PROTEIN_FASTA output FASTA file containing translated sequences for the predicted coding ORFs . ( default : None ) - v { 0 , 1 }, -- verbose { 0 , 1 } print the progress of the classification . 0 = silent , 1 = current step . ( default : 0 )","title":"rnasamba classify"},{"location":"usage/#examples","text":"Training a new classification model using Mus musculus data downloaded from GENCODE: rnasamba train -v 2 mouse_model.hdf5 gencode.vM21.pc_transcripts.fa gencode.vM21.lncRNA_transcripts.fa Classifying sequences using our pre-trained model ( partial_length_weights.hdf5 ) and saving the predicted proteins into a FASTA file: rnasamba classify -p predicted_proteins.fa classification.tsv input.fa partial_length_weights.hdf5 head classification . tsv sequence_name coding_score classification ENSMUST00000054910 0 . 99022 coding ENSMUST00000059648 0 . 84718 coding ENSMUST00000055537 0 . 99713 coding ENSMUST00000030975 0 . 85189 coding ENSMUST00000050754 0 . 02638 noncoding ENSMUST00000008011 0 . 14949 noncoding ENSMUST00000061643 0 . 03456 noncoding ENSMUST00000059704 0 . 89232 coding ENSMUST00000036304 0 . 03782 noncoding","title":"Examples"},{"location":"usage/#using-the-docker-image","text":"# Pull the Docker image to your computer : docker pull antoniopcamargo / rnasamba # Training example : docker run - ti --rm -v \"$(pwd):/app\" antoniopcamargo/rnasamba train -v 2 mouse_model.hdf5 gencode.vM21.pc_transcripts.fa gencode.vM21.lncRNA_transcripts.fa # Classification example : docker run - ti --rm -v \"$(pwd):/app\" antoniopcamargo/rnasamba classify -p predicted_proteins.fa classification.tsv input.fa full_length_weights.hdf5","title":"Using the Docker image"}]}